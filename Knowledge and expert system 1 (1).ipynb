{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b061435a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a85f3933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\patel\\anaconda3\\lib\\site-packages (4.41.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\patel\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in c:\\users\\patel\\anaconda3\\lib\\site-packages (from transformers) (0.23.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\patel\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\patel\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\patel\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\patel\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\patel\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\patel\\anaconda3\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\patel\\anaconda3\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\patel\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\patel\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\patel\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\patel\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\patel\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\patel\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\patel\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\patel\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "919dc9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b50ae11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\patel\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers.pipelines import PIPELINE_REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21e8abe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['audio-classification', 'automatic-speech-recognition', 'conversational', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-feature-extraction', 'image-segmentation', 'image-to-image', 'image-to-text', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'summarization', 'table-question-answering', 'text-classification', 'text-generation', 'text-to-audio', 'text-to-speech', 'text2text-generation', 'token-classification', 'translation', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection']\n"
     ]
    }
   ],
   "source": [
    "print(PIPELINE_REGISTRY.get_supported_tasks())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2998c10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Default Model for text-generation: \n",
      "{'model': {'pt': ('openai-community/gpt2', '6c0e608'), 'tf': ('openai-community/gpt2', '6c0e608')}}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDefault Model for text-generation: \")\n",
    "print(PIPELINE_REGISTRY.check_task('text-generation')[1].get('default'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "566a4705",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patel\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\patel\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Huggingface Cache directory is :  C:\\Users\\patel/.cache/huggingface/hub\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['.locks',\n",
       " 'models--dbmdz--bert-large-cased-finetuned-conll03-english',\n",
       " 'models--distilbert-base-uncased-finetuned-sst-2-english',\n",
       " 'models--distilgpt2',\n",
       " 'models--finiteautomata--bertweet-base-sentiment-analysis',\n",
       " 'models--gpt2',\n",
       " 'models--Jean-Baptiste--camembert-ner-with-dates',\n",
       " 'models--openai-community--gpt2',\n",
       " 'models--t5-small',\n",
       " 'version.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import os\n",
    "\n",
    "#Load a pipeline. This will download the model checkpoint from huggingface and cache it\n",
    "#locally on disk. If model is already available in cache, it will simply use the cached version\n",
    "#Download will usually take a long time, depending on network bandwidth\n",
    "\n",
    "text_gen = pipeline(\"text-generation\")\n",
    "\n",
    "#Cache usually available at : <<user-home>>.cache\\huggingface\\hub\n",
    "\n",
    "cache_dir = os.path.expanduser('~') + \"/.cache/huggingface/hub\"\n",
    "print(\"Huggingface Cache directory is : \", cache_dir)\n",
    "\n",
    "#Contents of cache directory\n",
    "os.listdir(cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a952fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'This is a amazing experience, I am so proud!\" - Michael B. \"Excellent job! I have been searching for a job at a retail store for some time, so I decided to go to a good store recently. I got an excellent customer'}]\n"
     ]
    }
   ],
   "source": [
    "text_game=text_gen(\"This is a amazing\")\n",
    "print(text_game)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1aac311f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'I love to learn Python! Learn Python is one of the hardest things to understand â€” and with great power comes great responsibility!\" This means that you need to be prepared to create a Python program and then have your C program. If you get bored,'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['.locks',\n",
       " 'models--dbmdz--bert-large-cased-finetuned-conll03-english',\n",
       " 'models--distilbert-base-uncased-finetuned-sst-2-english',\n",
       " 'models--distilgpt2',\n",
       " 'models--finiteautomata--bertweet-base-sentiment-analysis',\n",
       " 'models--gpt2',\n",
       " 'models--Jean-Baptiste--camembert-ner-with-dates',\n",
       " 'models--openai-community--gpt2',\n",
       " 'models--t5-small',\n",
       " 'version.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_gen = pipeline(task=\"text-generation\",\n",
    "                                model=\"gpt2\")\n",
    "\n",
    "text_game=text_gen(\"I love to learn Python\")\n",
    "\n",
    "print(text_game)\n",
    "\n",
    "#Contents of cache directory\n",
    "os.listdir(cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a35f0d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s =  pipeline(\"text-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fde634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"I love to learn Machine Learning\"\n",
    "generated = s(prompt, max_length=100, num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7b46103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'I love to learn Machine Learning! And while we\\'ve seen pretty clear examples of using it (see example 1 below) every so often, we\\'ve also seen lots of folks use an advanced algorithm such as Python or Groovy to create amazing neural network solutions that are used very much on the side of learning, but still use it without any knowledge of the language. It is, as such, a \"learn from the ground up\". I\\'m also very happy that a lot of people have taken the'}, {'generated_text': \"I love to learn Machine Learning; it's fun! I'm interested in teaching people from any skill level â€“ whether it was a business, engineering, computer science, programming or social science. This post has a collection of posts I started a month back in 2005. There's lots more for future reference!\"}, {'generated_text': 'I love to learn Machine Learning.'}]\n"
     ]
    }
   ],
   "source": [
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3b9900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0633a7b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
